{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998772d2-20fa-4620-a312-4527d51c0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:1\n",
    "Web scraping, also known as web harvesting, is the process of extracting data from websites automatically using software tools or bots. This process involves fetching data from web pages, analyzing the HTML content and extracting useful information.\n",
    "\n",
    "Web scraping is used for a variety of reasons, including:\n",
    "\n",
    "Data collection: Web scraping is commonly used to collect large amounts of data from websites for research, analysis, or marketing purposes.\n",
    "\n",
    "Price monitoring: Web scraping is used to monitor prices of products and services from various websites. This is commonly used by businesses to keep track of competitor prices and adjust their own prices accordingly.\n",
    "\n",
    "Content aggregation: Web scraping is used to aggregate content from multiple sources and display it on a single website or platform. This is commonly used by news websites, travel websites, and real estate websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa14fd-4b3e-430b-828a-f812b5a81fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:2\n",
    "There are various methods used for web scraping, including:\n",
    "\n",
    "Parsing HTML: This involves extracting data from the HTML code of a webpage using an HTML parser, such as BeautifulSoup or lxml.\n",
    "\n",
    "Using APIs: Many websites offer APIs (Application Programming Interfaces) that allow developers to access data directly in a structured format. This is a more efficient and reliable method compared to scraping the HTML.\n",
    "\n",
    "Automated web browsing: This involves using a web browser automation tool such as Selenium to simulate user interaction with a website, and extract data based on the resulting page content.\n",
    "\n",
    "HTTP requests: This method involves sending HTTP requests directly to a websiteâ€™s server and parsing the response content. This can be done using libraries such as Requests or urllib.\n",
    "\n",
    "DOM parsing: This involves extracting data from the Document Object Model (DOM) of a webpage, which is the structured representation of the HTML code that a browser uses to render a webpage.\n",
    "\n",
    "Scraping data feeds: This involves extracting data from data feeds such as RSS or Atom feeds that are published by websites.\n",
    "\n",
    "Text pattern matching: This method involves using regular expressions or other text pattern matching techniques to extract specific data from webpage content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe06133-8ee6-4e1d-afca-309810336397",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:3\n",
    "Beautiful Soup is a Python library used for web scraping purposes. It is a popular tool for parsing HTML and XML documents and extracting useful data from them.\n",
    "\n",
    "Beautiful Soup allows programmers to extract specific elements of a webpage, such as text, images, links, and other HTML tags, using a simple and intuitive syntax. It also handles poorly formatted HTML code and can be used to navigate complex HTML structures.\n",
    "\n",
    "Beautiful Soup is used for a variety of reasons, including:\n",
    "\n",
    "Data extraction: Beautiful Soup is commonly used to extract data from web pages for data analysis or other purposes.\n",
    "\n",
    "Web scraping: Beautiful Soup can be used to automate the process of collecting data from multiple web pages.\n",
    "\n",
    "Parsing HTML: Beautiful Soup is a powerful tool for parsing HTML and XML documents, even if they are poorly formatted.\n",
    "\n",
    "Easy to use: Beautiful Soup is user-friendly and easy to learn, making it a popular choice for beginners and experienced programmers alike.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350a309-5c50-4cde-8c69-3075967aa116",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:4\n",
    "Flask is a lightweight web application framework in Python that is commonly used for building web applications, including web scraping projects. Flask is a popular choice for web scraping projects because of its simplicity, flexibility, and ease of use.\n",
    "\n",
    "In a web scraping project, Flask can be used to create a simple web application that can be accessed from a web browser or other application. This web application can be used to perform the web scraping tasks, and display the results to the user.\n",
    "\n",
    "Flask is also useful for handling user input, such as search queries, and can be used to store and retrieve data from a database, if necessary. Flask can also handle multiple requests concurrently, making it well-suited for web scraping projects that require scraping data from multiple web pages simultaneously.\n",
    "\n",
    "Additionally, Flask can be easily integrated with other Python libraries commonly used in web scraping, such as Beautiful Soup and Scrapy, making it a versatile tool for web scraping projects.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
